{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Basic Statistics and Data Types - Sampling \n",
    " \n",
    "\n",
    "## Lesson Objectives\n",
    "\n",
    "-\tAfter completing this lesson, you should be able to:\n",
    "-\tPerform standard sampling on any RDD \n",
    "-\tSplit any RDD randomly into subsets \n",
    "-\tPerform stratified sampling on RDDs of key-value pairs \n",
    "\n",
    "\n",
    "## Sampling \n",
    "\n",
    "-\tCan be performed on any RDD \n",
    "- Returns a sampled subset of an RDD\n",
    "-\tSampling with or without replacement\n",
    "- Fraction:\n",
    "-\twithout replacement - expected size of the sample as fraction of RDD's size \n",
    "-\twith replacement - expected number of times each element is chosen\n",
    "-\tCan be used on bootstrapping procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elements = ParallelCollectionRDD[0] at parallelize at <console>:32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// A Simple Sampling \n",
    "\n",
    "import org.apache.spark.mllib.linalg.{Vector, Vectors}\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "val elements: RDD[Vector] = sc.parallelize(Array(\n",
    "    Vectors.dense(4.0,7.0,13.0),\n",
    "    Vectors.dense(-2.0,8.0,4.0),\n",
    "    Vectors.dense(3.0,-11.0,19.0)))\n",
    "\n",
    "elements.sample(withReplacement=false, fraction=0.5, seed=10L).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements.sample(withReplacement=false, fraction=0.5, seed=7L).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-2.0,8.0,4.0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements.sample(withReplacement=false, fraction=0.5, seed=64L).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split\n",
    "\n",
    "-\tCan be performed on any RDD\n",
    "-\tReturns an array of RDDs\n",
    "- Weights for the split will be normalized if they do not add up to 1\n",
    "-\tUseful for splitting a data set into training, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data = ParallelCollectionRDD[4] at parallelize at <console>:29\n",
       "splits = Array(MapPartitionsRDD[5] at randomSplit at <console>:30, MapPartitionsRDD[6] at randomSplit at <console>:30, MapPartitionsRDD[7] at randomSplit at <console>:30)\n",
       "training = MapPartitionsRDD[5] at randomSplit at <console>:30\n",
       "test = MapPartitionsRDD[6] at randomSplit at <console>:30\n",
       "validation = MapPartitionsRDD[7] at randomSplit at <console>:30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array(600280, 200029, 199691)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = sc.parallelize(1 to 1000000)\n",
    "val splits = data.randomSplit(Array(0.6, 0.2, 0.2), seed = 13L)\n",
    "\n",
    "val training = splits(0)\n",
    "val test = splits(1)\n",
    "val validation = splits(2)\n",
    "\n",
    "splits.map(_.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling \n",
    "\n",
    "-\tCan be performed on RDDs of key-value pairs \n",
    "-\tThink of keys as labels and values as an specific attribute\n",
    "- Two supported methods defined in `PairRDDFunctions`:\n",
    "-\t`sampleByKey` requires only one pass over the data and provides an expected sample size\n",
    "-\t`sampleByKeyExact` provides the exact sampling size with 99.99% confidence but requires significantly more resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rows = ParallelCollectionRDD[11] at parallelize at <console>:38\n",
       "fractions = Map(0 -> 1.0, 1 -> 0.5)\n",
       "approxSample = MapPartitionsRDD[14] at sampleByKeyExact at <console>:47\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array((0,[1.0,2.0]), (1,[7.0,8.0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.mllib.linalg.distributed.IndexedRow\n",
    "\n",
    "val rows: RDD[IndexedRow] = sc.parallelize(Array(\n",
    "    IndexedRow(0, Vectors.dense(1.0,2.0)),\n",
    "    IndexedRow(1, Vectors.dense(4.0,5.0)),\n",
    "    IndexedRow(1, Vectors.dense(7.0,8.0))))\n",
    "\n",
    "val fractions: Map[Long, Double] = Map(0L -> 1.0, 1L -> 0.5)\n",
    "\n",
    "val approxSample = rows.map{\n",
    "    case IndexedRow(index, vec) => (index, vec)\n",
    "}.sampleByKeyExact(withReplacement = false, fractions, 9L)\n",
    "\n",
    "approxSample.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary: \n",
    "\n",
    "-\tHaving completed this lesson, you should now be able to:\n",
    "-\tPerform standard sampling on any RDD\n",
    "-\tSplit any RDD randomly into subsets\n",
    "-\tPerform stratified sampling on RDDs of key-value pairs\n",
    "\n",
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
